{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a0a6820a2014305b3799695f4e1e214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6495fcf7423c4d999c484d4aa16d4408",
              "IPY_MODEL_fc993094a6f1426ea39269b6a607c03e",
              "IPY_MODEL_30d8f5c975814299b13e40d50b65f135"
            ],
            "layout": "IPY_MODEL_ffa480bac71f45a0a2ee56c4081badd9"
          }
        },
        "6495fcf7423c4d999c484d4aa16d4408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4f41fd7276f4e4eb91083dbff376da9",
            "placeholder": "​",
            "style": "IPY_MODEL_afd727a8dcac4939abec88ac6e3be85c",
            "value": "Batches: 100%"
          }
        },
        "fc993094a6f1426ea39269b6a607c03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40da48c0c2474a82a86110ff487ee539",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2aab4aa3e174992b7a1ea7a3451bd4b",
            "value": 52
          }
        },
        "30d8f5c975814299b13e40d50b65f135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f063cf654444ec96546ba1eddab68d",
            "placeholder": "​",
            "style": "IPY_MODEL_17f9c71cc4594f02b098ae9e7472d59a",
            "value": " 52/52 [00:33&lt;00:00,  3.62it/s]"
          }
        },
        "ffa480bac71f45a0a2ee56c4081badd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f41fd7276f4e4eb91083dbff376da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd727a8dcac4939abec88ac6e3be85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40da48c0c2474a82a86110ff487ee539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2aab4aa3e174992b7a1ea7a3451bd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92f063cf654444ec96546ba1eddab68d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f9c71cc4594f02b098ae9e7472d59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e50df477c1b845f09f2b535c01016517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3178be02488c4a1c99af0531615beca9",
              "IPY_MODEL_64e6dac1744845c1ac7f3c912b080440",
              "IPY_MODEL_feefcd216c9d45a6b9f9bc18c8c549e1"
            ],
            "layout": "IPY_MODEL_04152e4534154f5d86529d3d9fa599ea"
          }
        },
        "3178be02488c4a1c99af0531615beca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd1b6b6f75d74c7da8edc673cc8c79bc",
            "placeholder": "​",
            "style": "IPY_MODEL_65055092377e42deac005abd755ea5fc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "64e6dac1744845c1ac7f3c912b080440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2410229054451e8e8182a17803a295",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aed2b00d14864d8894a419ec049b7fde",
            "value": 2
          }
        },
        "feefcd216c9d45a6b9f9bc18c8c549e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9209f1ee1f52476c9b638d282b35af9f",
            "placeholder": "​",
            "style": "IPY_MODEL_7dbc22b2844049feba23db42731227df",
            "value": " 2/2 [00:29&lt;00:00, 13.60s/it]"
          }
        },
        "04152e4534154f5d86529d3d9fa599ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1b6b6f75d74c7da8edc673cc8c79bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65055092377e42deac005abd755ea5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2410229054451e8e8182a17803a295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed2b00d14864d8894a419ec049b7fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9209f1ee1f52476c9b638d282b35af9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dbc22b2844049feba23db42731227df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doffena/Large-Language-Models/blob/main/VERS%C4%B0ON2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings, sys, torch\n",
        "warnings.filterwarnings(\"ignore\", message=r\".*HF_TOKEN.*\", category=UserWarning)\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "rx2Nf1tUHsUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e726f15-7a19-4583-a49f-556ed8cb7e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Torch: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CLEAN + STABLE INSTALL (run once per fresh runtime) =====\n",
        "!pip -q uninstall -y faiss-cpu faiss sentence-transformers gradio numpy \\\n",
        "  datasets transformers accelerate huggingface_hub peft bitsandbytes triton sentencepiece safetensors\n",
        "\n",
        "# (Colab bazen \"invalid distribution ~ip\" kalıntısı bırakıyor; temizle)\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/~ip*\n",
        "\n",
        "# FAISS için kritik: NumPy 2 değil, <2\n",
        "!pip -q install \"numpy<2.0\"\n",
        "\n",
        "# Senin sabitlediğin çekirdek kütüphaneler\n",
        "!pip -q install datasets==2.21.0 transformers==4.47.1 accelerate==1.2.1 huggingface_hub==0.26.5 peft==0.13.2\n",
        "\n",
        "# RAG için gerekenler (faiss-cpu + sentence-transformers + gradio)\n",
        "!pip -q install faiss-cpu sentence-transformers gradio\n",
        "\n",
        "import numpy as np\n",
        "print(\"numpy version:\", np.__version__)"
      ],
      "metadata": {
        "id": "3saw86qpHsxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab21809-0e8d-4f3a-e94c-dedb2c460366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping faiss as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping sentencepiece as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "torchtune 0.6.1 requires huggingface_hub[hf_transfer], which is not installed.\n",
            "torchtune 0.6.1 requires safetensors, which is not installed.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, which is not installed.\n",
            "diffusers 0.36.0 requires safetensors>=0.3.1, which is not installed.\n",
            "timm 1.0.22 requires huggingface_hub, which is not installed.\n",
            "timm 1.0.22 requires safetensors, which is not installed.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.26.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mnumpy version: 1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import hashlib\n",
        "import unicodedata\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "from datasets import load_dataset\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# (Opsiyonel) Colab'da HF_TOKEN uyarısını bastırmak istersen:\n",
        "warnings.filterwarnings(\"ignore\", message=r\".*HF_TOKEN.*\", category=UserWarning)\n",
        "\n",
        "# -----------------------\n",
        "# DATA SOURCE SETTINGS\n",
        "# -----------------------\n",
        "# Öncelik: dataset'i HF ID ile çek (daha stabil)\n",
        "DATASET_ID = os.environ.get(\"DATASET_ID\", \"mertbozkurt/turkish-recipe\")\n",
        "\n",
        "# Fallback: senin kullandığın düz txt dosya yolu (HF hub file)\n",
        "DATASET_TEXT_FILE = os.environ.get(\n",
        "    \"DATASET_TEXT_FILE\",\n",
        "    \"hf://datasets/mertbozkurt/turkish-recipe/datav3.txt\"\n",
        ")\n",
        "\n",
        "# Cache (Colab local disk)\n",
        "CACHE_DIR = os.environ.get(\"CACHE_DIR\", \"/content/recipe_cache\")\n",
        "CACHE_PATH = os.path.join(CACHE_DIR, \"recipes_v3.jsonl\")\n",
        "\n",
        "# Matching rules\n",
        "FUZZY_THRESHOLD = int(os.environ.get(\"FUZZY_THRESHOLD\", \"90\"))\n",
        "ENABLE_FUZZY = False  # difflib fuzzy büyük listelerde pahalı\n",
        "NOT_FOUND_MSG = \"Bu tarif veri setimde bulunmuyor.\"\n",
        "SUGGEST_PREFIX = \"Bu tarif veri setimde bulunmuyor.\\n\\nBunu mu demek istediniz?\"\n",
        "\n",
        "\n",
        "# Training toggle: DO NOT start training unless you set this to True\n",
        "RUN_TRAINING = False\n",
        "\n",
        "# -----------------------\n",
        "# PARSING REGEX\n",
        "# -----------------------\n",
        "_RECIPE_START_RE = re.compile(r\"^(?P<title>.+?)\\s+nas[ıi]l\\s+yap[ıi]l[ıi]r\\?\\s*$\", re.IGNORECASE)\n",
        "_ING_HEADER_RE = re.compile(r\"gerekli\\s+malzemeler\\s*:\\s*$\", re.IGNORECASE)\n",
        "_STEPS_HEADER_RE = re.compile(r\"yap[ıi]l[ıi][şs][ıi]\\s*:\\s*$\", re.IGNORECASE)\n",
        "_CATEGORY_RE = re.compile(r\"^kategori\\s*:\\s*(?P<cat>.+)$\", re.IGNORECASE)\n",
        "_GARBAGE_PAT = re.compile(\n",
        "    r\"(Bu Tariflere de Göz At|Videolu Tarif|Aşağıdan Hemen İzleyebilirsiniz|Yemek Tarifleri|Püf Noktaları)\",\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "_TR_FOLD_MAP = str.maketrans({\n",
        "    \"ç\": \"c\", \"ğ\": \"g\", \"ı\": \"i\", \"İ\": \"i\", \"ö\": \"o\", \"ş\": \"s\", \"ü\": \"u\",\n",
        "    \"Ç\": \"c\", \"Ğ\": \"g\", \"Ö\": \"o\", \"Ş\": \"s\", \"Ü\": \"u\",\n",
        "})\n",
        "\n",
        "_QUERY_STRIP_PATTERNS = [\n",
        "    r\"\\btarif(?:i|ini|im|imı|imi)?\\b\",\n",
        "    r\"\\bnasil yapilir\\b\",\n",
        "    r\"\\bnasıl yapılır\\b\",\n",
        "    r\"\\bnedir\\b\",\n",
        "    r\"\\bnasil\\b\",\n",
        "    r\"\\bnasıl\\b\",\n",
        "]\n",
        "\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = s.casefold()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = s.translate(_TR_FOLD_MAP)\n",
        "    s = re.sub(r\"[^0-9a-z\\s]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def extract_recipe_name(user_text: str) -> str:\n",
        "    t = normalize_text(user_text)\n",
        "    if not t:\n",
        "        return \"\"\n",
        "    for pat in _QUERY_STRIP_PATTERNS:\n",
        "        t = re.sub(pat, \" \", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t if len(t) >= 3 else \"\"\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Recipe:\n",
        "    title: str\n",
        "    category: str\n",
        "    ingredients: List[str]\n",
        "    instructions: List[str]\n",
        "    norm_title: str\n",
        "\n",
        "\n",
        "def _fingerprint(r: Recipe) -> str:\n",
        "    payload = {\n",
        "        \"t\": r.norm_title,\n",
        "        \"c\": (r.category or \"\").strip(),\n",
        "        \"i\": [x.strip() for x in (r.ingredients or [])],\n",
        "        \"s\": [x.strip() for x in (r.instructions or [])],\n",
        "    }\n",
        "    b = json.dumps(payload, ensure_ascii=False, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "    return hashlib.sha1(b).hexdigest()\n",
        "\n",
        "\n",
        "def _safe_read_cache() -> Optional[List[Recipe]]:\n",
        "    if not os.path.exists(CACHE_PATH):\n",
        "        return None\n",
        "    recipes: List[Recipe] = []\n",
        "    with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                recipes.append(\n",
        "                    Recipe(\n",
        "                        title=str(obj.get(\"title\", \"\")),\n",
        "                        category=str(obj.get(\"category\", \"\")),\n",
        "                        ingredients=list(obj.get(\"ingredients\", []) or []),\n",
        "                        instructions=list(obj.get(\"instructions\", []) or []),\n",
        "                        norm_title=str(obj.get(\"norm_title\", \"\")),\n",
        "                    )\n",
        "                )\n",
        "            except Exception:\n",
        "                # bozuk satır varsa atla\n",
        "                continue\n",
        "    return recipes\n",
        "\n",
        "\n",
        "def _write_cache(recipes: List[Recipe]) -> None:\n",
        "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "    with open(CACHE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in recipes:\n",
        "            f.write(\n",
        "                json.dumps(\n",
        "                    {\n",
        "                        \"title\": r.title,\n",
        "                        \"category\": r.category,\n",
        "                        \"ingredients\": r.ingredients,\n",
        "                        \"instructions\": r.instructions,\n",
        "                        \"norm_title\": r.norm_title,\n",
        "                    },\n",
        "                    ensure_ascii=False,\n",
        "                )\n",
        "                + \"\\n\"\n",
        "            )\n",
        "\n",
        "\n",
        "def _load_lines_from_hf() -> List[str]:\n",
        "    \"\"\"\n",
        "    Önce structured HF dataset'i dener.\n",
        "    Eğer olmazsa, hf://.../datav3.txt text loader fallback yapar.\n",
        "    \"\"\"\n",
        "    # 1) Try structured dataset\n",
        "    try:\n",
        "        ds = load_dataset(DATASET_ID, split=\"train\")\n",
        "        cols = set(ds.column_names)\n",
        "\n",
        "        # Beklenen ihtimaller:\n",
        "        # - \"text\" tek kolon (tam tarif)\n",
        "        # - \"title/materials/how-to/category\" gibi kolonlar\n",
        "        if \"text\" in cols:\n",
        "            return [str(x or \"\").strip() for x in ds[\"text\"]]\n",
        "        if \"content\" in cols:\n",
        "            return [str(x or \"\").strip() for x in ds[\"content\"]]\n",
        "\n",
        "        # Eğer alanlı dataset ise \"satır\" formatına biz çeviririz:\n",
        "        # (Bu satırlar aşağıdaki parse logic ile değil, doğrudan recipe objeye de çevrilebilir,\n",
        "        # ama senin mevcut parser'ın datav3 formatına göre yazıldığı için burada \"line stream\" üretmiyoruz.)\n",
        "        # Bu durumda fallback'a geçiyoruz.\n",
        "        raise ValueError(f\"Dataset columns not supported for text-parse: {cols}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # 2) Fallback to datav3.txt as text lines\n",
        "        ds = load_dataset(\"text\", data_files={\"train\": DATASET_TEXT_FILE}, split=\"train\")\n",
        "        return [str(row.get(\"text\", \"\")).strip() for row in ds]\n",
        "\n",
        "\n",
        "def load_recipes_v3(force_rebuild: bool = False) -> List[Recipe]:\n",
        "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "    if not force_rebuild:\n",
        "        cached = _safe_read_cache()\n",
        "        if cached and len(cached) > 0:\n",
        "            return cached\n",
        "\n",
        "    lines = _load_lines_from_hf()\n",
        "\n",
        "    recipes: List[Recipe] = []\n",
        "    cur_title = \"\"\n",
        "    cur_category = \"\"\n",
        "    ingredients: List[str] = []\n",
        "    steps: List[str] = []\n",
        "    mode: Optional[str] = None\n",
        "\n",
        "    def flush() -> None:\n",
        "        nonlocal cur_title, cur_category, ingredients, steps, mode\n",
        "        if cur_title:\n",
        "            recipes.append(\n",
        "                Recipe(\n",
        "                    title=cur_title,\n",
        "                    category=cur_category,\n",
        "                    ingredients=ingredients[:],\n",
        "                    instructions=steps[:],\n",
        "                    norm_title=normalize_text(cur_title),\n",
        "                )\n",
        "            )\n",
        "        cur_title = \"\"\n",
        "        cur_category = \"\"\n",
        "        ingredients = []\n",
        "        steps = []\n",
        "        mode = None\n",
        "\n",
        "    for line in lines:\n",
        "        line = (line or \"\").strip()\n",
        "\n",
        "        if _GARBAGE_PAT.search(line):\n",
        "            continue\n",
        "\n",
        "        if not line:\n",
        "            if cur_title:\n",
        "                flush()\n",
        "            continue\n",
        "\n",
        "        m = _RECIPE_START_RE.match(line)\n",
        "        if m:\n",
        "            if cur_title:\n",
        "                flush()\n",
        "            cur_title = str(m.group(\"title\")).strip()\n",
        "            mode = None\n",
        "            continue\n",
        "\n",
        "        if not cur_title:\n",
        "            continue\n",
        "\n",
        "        mc = _CATEGORY_RE.match(line)\n",
        "        if mc:\n",
        "            cur_category = str(mc.group(\"cat\")).strip()\n",
        "            continue\n",
        "\n",
        "        if _ING_HEADER_RE.search(line):\n",
        "            mode = \"ing\"\n",
        "            continue\n",
        "        if _STEPS_HEADER_RE.search(line):\n",
        "            mode = \"steps\"\n",
        "            continue\n",
        "\n",
        "        if mode == \"ing\":\n",
        "            ingredients.append(line.lstrip(\"-•\").strip())\n",
        "        elif mode == \"steps\":\n",
        "            steps.append(line.strip())\n",
        "        else:\n",
        "            steps.append(line.strip())\n",
        "\n",
        "    if cur_title:\n",
        "        flush()\n",
        "\n",
        "    # dedupe exact duplicates\n",
        "    seen = set()\n",
        "    deduped: List[Recipe] = []\n",
        "    for r in recipes:\n",
        "        fp = _fingerprint(r)\n",
        "        if fp in seen:\n",
        "            continue\n",
        "        seen.add(fp)\n",
        "        deduped.append(r)\n",
        "    recipes = deduped\n",
        "\n",
        "    _write_cache(recipes)\n",
        "    return recipes\n",
        "\n",
        "\n",
        "def format_recipe_block(r: Recipe) -> str:\n",
        "    parts: List[str] = []\n",
        "    parts.append(\"Tarifin Adı:\")\n",
        "    parts.append(r.title.strip())\n",
        "    parts.append(\"\")\n",
        "    parts.append(\"Malzemeler:\")\n",
        "    parts.extend([f\"- {x}\" for x in (r.ingredients or [])] or [\"(bulunamadı)\"])\n",
        "    parts.append(\"\")\n",
        "    parts.append(\"Yapılışı:\")\n",
        "    if r.instructions:\n",
        "        parts.extend([f\"{i+1}. {x}\" for i, x in enumerate(r.instructions)])\n",
        "    else:\n",
        "        parts.append(\"(bulunamadı)\")\n",
        "    return \"\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "def build_sft_example(r: Recipe) -> dict:\n",
        "    prompt = f\"[INST] {r.title} tarifi [/INST]\"\n",
        "    completion = format_recipe_block(r)\n",
        "    return {\"text\": prompt + \"\\n\" + completion}\n",
        "\n",
        "\n",
        "class StrictMatcher:\n",
        "    def __init__(self, recipes: List[Recipe]):\n",
        "        self.recipes = recipes\n",
        "        self.norm_titles = [r.norm_title for r in recipes]\n",
        "        self.by_norm: Dict[str, List[int]] = {}\n",
        "        for i, t in enumerate(self.norm_titles):\n",
        "            self.by_norm.setdefault(t, []).append(i)\n",
        "\n",
        "    def _pick_best_exact(self, idxs: List[int]) -> Optional[int]:\n",
        "        if not idxs:\n",
        "            return None\n",
        "        if len(idxs) == 1:\n",
        "            return idxs[0]\n",
        "\n",
        "        def score(i: int):\n",
        "            r = self.recipes[i]\n",
        "            return (len(r.instructions or []), len(r.ingredients or []))\n",
        "        return max(idxs, key=score)\n",
        "\n",
        "    def match(self, user_text: str) -> Optional[Recipe]:\n",
        "        candidate = extract_recipe_name(user_text)\n",
        "        if not candidate:\n",
        "            return None\n",
        "        q = normalize_text(candidate)\n",
        "        if not q:\n",
        "            return None\n",
        "\n",
        "        # 1) exact\n",
        "        ex = self._pick_best_exact(self.by_norm.get(q, []))\n",
        "        if ex is not None:\n",
        "            return self.recipes[ex]\n",
        "\n",
        "        # 2) contains (unique)\n",
        "        hits = [i for i, t in enumerate(self.norm_titles) if q in t]\n",
        "        if len(hits) == 1:\n",
        "            return self.recipes[hits[0]]\n",
        "\n",
        "        # 3) optional fuzzy (kapalı tutmak OK)\n",
        "        if not ENABLE_FUZZY or len(q) < 4:\n",
        "            return None\n",
        "\n",
        "        best_idx = None\n",
        "        best_score = -1\n",
        "        second_score = -1\n",
        "        for i, t in enumerate(self.norm_titles):\n",
        "            s = int(SequenceMatcher(None, q, t).ratio() * 100)\n",
        "            if s > best_score:\n",
        "                second_score = best_score\n",
        "                best_score = s\n",
        "                best_idx = i\n",
        "            elif s > second_score:\n",
        "                second_score = s\n",
        "\n",
        "        if best_idx is None:\n",
        "            return None\n",
        "        if best_score >= FUZZY_THRESHOLD and second_score != best_score:\n",
        "            return self.recipes[int(best_idx)]\n",
        "        return None\n",
        "\n",
        "    def suggest(self, user_text: str, top_n: int = 6, min_score: int = 55) -> List[Recipe]:\n",
        "        candidate = extract_recipe_name(user_text)\n",
        "        q = normalize_text(candidate)\n",
        "        if not q:\n",
        "            return []\n",
        "\n",
        "        scored = []\n",
        "        for i, t in enumerate(self.norm_titles):\n",
        "            s = int(SequenceMatcher(None, q, t).ratio() * 100)\n",
        "            scored.append((s, i))\n",
        "        scored.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "        out: List[Recipe] = []\n",
        "        used = set()\n",
        "        for s, i in scored[: top_n * 6]:\n",
        "            if s < min_score:\n",
        "                continue\n",
        "            r = self.recipes[i]\n",
        "            if r.norm_title in used:\n",
        "                continue\n",
        "            used.add(r.norm_title)\n",
        "            out.append(r)\n",
        "            if len(out) >= top_n:\n",
        "                break\n",
        "        return out\n",
        "\n",
        "\n",
        "def format_suggestions(recipes: List[Recipe]) -> str:\n",
        "    if not recipes:\n",
        "        return NOT_FOUND_MSG\n",
        "    lines = [SUGGEST_PREFIX]\n",
        "    for i, r in enumerate(recipes, 1):\n",
        "        lines.append(f\"{i}) {r.title}\")\n",
        "    lines.append(\"\\nBirini seçmek için numarasını yazabilirsiniz (örn: 1) veya başlığı aynen yazabilirsiniz.\")\n",
        "    return \"\\n\".join(lines).strip()\n"
      ],
      "metadata": {
        "id": "6EQAPjHXHvBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load authoritative recipes (first run will download+parse; cache used afterwards)\n",
        "try:\n",
        "    RECIPES = load_recipes_v3(force_rebuild=False)\n",
        "\n",
        "    # Eğer cache bozuk/boş geldiyse otomatik rebuild dene\n",
        "    if not RECIPES or len(RECIPES) == 0:\n",
        "        print(\" Cache empty or parse returned 0 recipes. Rebuilding cache...\")\n",
        "        RECIPES = load_recipes_v3(force_rebuild=True)\n",
        "\n",
        "    MATCHER = StrictMatcher(RECIPES)\n",
        "\n",
        "    print(\" Loaded recipes:\", len(RECIPES))\n",
        "    print(\" Cache path:\", CACHE_PATH)\n",
        "\n",
        "    # Hızlı sanity check (ilk 5 başlık)\n",
        "    print(\"\\n Sample titles:\")\n",
        "    for r in RECIPES[:5]:\n",
        "        print(\" -\", r.title)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\" Failed to load/parse recipes.\")\n",
        "    print(\"Error:\", repr(e))\n",
        "    print(\"\\n Tips:\")\n",
        "    print(\" - If this is the first run, download can take time.\")\n",
        "    print(\" - Try force rebuild: RECIPES = load_recipes_v3(force_rebuild=True)\")\n",
        "    print(\" - If using hf:// fallback, ensure datasets version supports it.\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "sq5YZhCOHv5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6427ea5-dbc4-4017-ae23-9ab7664c92e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded recipes: 3311\n",
            " Cache path: /content/recipe_cache/recipes_v3.jsonl\n",
            "\n",
            " Sample titles:\n",
            " - Sodalı Köfte\n",
            " - Hatay Kağıt Kebabı\n",
            " - Piliç Topkapı\n",
            " - Sebzeli Soslu Tavuk Yemeği\n",
            " - Tire Şiş Köfte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy 2.x -> 1.x düşür (faiss uyumu için)\n",
        "!python -m pip -q uninstall -y numpy faiss-cpu\n",
        "!python -m pip -q install \"numpy<2\" --no-cache-dir\n",
        "!python -m pip -q install faiss-cpu==1.8.0 --no-cache-dir\n",
        "\n",
        "import numpy as np\n",
        "print(\" numpy version:\", np.__version__)\n",
        "\n",
        "import faiss\n",
        "print(\" faiss imported OK\")"
      ],
      "metadata": {
        "id": "Ii-NMPUlHxZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefdb72a-ec77-454d-a5d4-1b71b89b2c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m278.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h numpy version: 1.26.4\n",
            " faiss imported OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip -q install faiss-cpu==1.8.0 sentence-transformers==3.0.1"
      ],
      "metadata": {
        "id": "yCOKVmKKHzQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Embedding modeli (Türkçe için iyi, hızlı)\n",
        "EMB_MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
        "\n",
        "# RAG ayarları\n",
        "TOP_K = 5\n",
        "USE_GPU_FOR_EMB = True  # Colab GPU varsa hızlanır\n",
        "\n",
        "# 1) Recipe -> tek metin haline getirme (retrieval için)\n",
        "def recipe_to_doc(r: Recipe) -> str:\n",
        "    # Retrieval kalitesi için title + category + ingredients + instructions tek metin\n",
        "    ing = \"\\n\".join([f\"- {x}\" for x in (r.ingredients or [])])\n",
        "    steps = \"\\n\".join([f\"{i+1}. {x}\" for i, x in enumerate(r.instructions or [])])\n",
        "    return (\n",
        "        f\"Başlık: {r.title}\\n\"\n",
        "        f\"Kategori: {r.category or ''}\\n\"\n",
        "        f\"Malzemeler:\\n{ing}\\n\"\n",
        "        f\"Yapılış:\\n{steps}\\n\"\n",
        "    ).strip()\n",
        "\n",
        "DOCS = [recipe_to_doc(r) for r in RECIPES]\n",
        "print(\"Docs prepared:\", len(DOCS))\n",
        "\n",
        "# 2) Embedding modeli yükle\n",
        "emb_model = SentenceTransformer(EMB_MODEL_NAME, device=(\"cuda\" if (USE_GPU_FOR_EMB and torch.cuda.is_available()) else \"cpu\"))\n",
        "\n",
        "# E5 için query/doc prefix iyi çalışır\n",
        "DOC_EMB_TEXTS = [(\"passage: \" + d) for d in DOCS]\n",
        "\n",
        "# 3) Embed + normalize (cosine similarity için)\n",
        "doc_emb = emb_model.encode(\n",
        "    DOC_EMB_TEXTS,\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ").astype(\"float32\")\n",
        "\n",
        "# 4) FAISS index (cosine = inner product + normalized)\n",
        "dim = doc_emb.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(doc_emb)\n",
        "\n",
        "print(\" FAISS index ready.\")\n",
        "print(\"Embedding dim:\", dim, \"| Index size:\", index.ntotal)"
      ],
      "metadata": {
        "id": "FUjoZ8vaH0yw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "4a0a6820a2014305b3799695f4e1e214",
            "6495fcf7423c4d999c484d4aa16d4408",
            "fc993094a6f1426ea39269b6a607c03e",
            "30d8f5c975814299b13e40d50b65f135",
            "ffa480bac71f45a0a2ee56c4081badd9",
            "c4f41fd7276f4e4eb91083dbff376da9",
            "afd727a8dcac4939abec88ac6e3be85c",
            "40da48c0c2474a82a86110ff487ee539",
            "a2aab4aa3e174992b7a1ea7a3451bd4b",
            "92f063cf654444ec96546ba1eddab68d",
            "17f9c71cc4594f02b098ae9e7472d59a"
          ]
        },
        "outputId": "37cb3c58-531b-4668-bf96-8469d8e60344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docs prepared: 3311\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/52 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0a6820a2014305b3799695f4e1e214"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FAISS index ready.\n",
            "Embedding dim: 384 | Index size: 3311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# --- Guard regex'leri ---\n",
        "_TIME_Q_RE = re.compile(r\"(airfryer|air fryer|kaç\\s*(dk|dakika|derece)|\\b\\d+\\s*(dk|dakika|°|derece)\\b)\", re.IGNORECASE)\n",
        "_PORTION_Q_RE = re.compile(r\"(\\b\\d+\\s*kişilik\\b|\\bporsiyon\\b)\", re.IGNORECASE)\n",
        "_SUGGEST_Q_RE = re.compile(r\"(\\böner\\b|\\böneri\\b|\\bne\\s*yapayım\\b|\\bönerir\\s*misin\\b)\", re.IGNORECASE)\n",
        "_RECIPE_REQ_RE = re.compile(r\"(tarif|tarifi|malzeme|yapılış|yapilis|nasıl|nasil)\", re.IGNORECASE)\n",
        "\n",
        "def retrieve_recipes_safe(query: str, top_k: int = 5, score_threshold: float = 0.35, min_margin: float = 0.02):\n",
        "    \"\"\"\n",
        "    - score_threshold: alakasız retrieval'ı keser\n",
        "    - min_margin: top1 ile top2 çok yakınsa (belirsizlik) keser\n",
        "    \"\"\"\n",
        "    q0 = (query or \"\").strip()\n",
        "    if not q0:\n",
        "        return []\n",
        "\n",
        "    # Sorudan \"tarif adı\" gibi kısmı ayıklamaya çalış (yoksa query'nin kendisi)\n",
        "    q_clean = extract_recipe_name(q0) or q0\n",
        "\n",
        "    q_emb = emb_model.encode(\n",
        "        [\"query: \" + q_clean],\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    scores, idxs = index.search(q_emb, top_k)\n",
        "    scores = scores[0].tolist()\n",
        "    idxs = idxs[0].tolist()\n",
        "\n",
        "    if not scores or scores[0] < score_threshold:\n",
        "        return []\n",
        "    if len(scores) >= 2 and (scores[0] - scores[1]) < min_margin:\n",
        "        return []\n",
        "\n",
        "    out = []\n",
        "    for s, i in zip(scores, idxs):\n",
        "        if i < 0:\n",
        "            continue\n",
        "        out.append((float(s), RECIPES[int(i)]))\n",
        "    return out\n",
        "\n",
        "\n",
        "# --------- LLM (Qwen) yükle ----------\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "LLM_NAME = os.environ.get(\"LLM_NAME\", \"Qwen/Qwen2.5-3B-Instruct\")  # 7B ağırsa 3B daha stabil\n",
        "tokenizer_llm = AutoTokenizer.from_pretrained(LLM_NAME, use_fast=True, trust_remote_code=True)\n",
        "model_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_NAME,\n",
        "    torch_dtype=(torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16),\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model_llm.eval()\n",
        "\n",
        "\n",
        "LAST_SUGGESTIONS: List[Recipe] = []\n",
        "\n",
        "def _token_overlap(query: str, title: str) -> int:\n",
        "    q = normalize_text(extract_recipe_name(query) or query)\n",
        "    t = normalize_text(title)\n",
        "    q_tokens = set(q.split())\n",
        "    t_tokens = set(t.split())\n",
        "    return len(q_tokens & t_tokens)\n",
        "\n",
        "def format_suggestions(recipes: List[Recipe]) -> str:\n",
        "    if not recipes:\n",
        "        return NOT_FOUND_MSG\n",
        "    lines = [SUGGEST_PREFIX]\n",
        "    for i, r in enumerate(recipes, 1):\n",
        "        lines.append(f\"{i}) {r.title}\")\n",
        "    lines.append(\"\\nSeçmek için numara yaz (örn: 1) veya başlığı aynen yaz.\")\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "\n",
        "\n",
        "def rag_answer_guarded(user_question: str, top_k: int = 3) -> str:\n",
        "    global LAST_SUGGESTIONS\n",
        "\n",
        "    q = (user_question or \"\").strip()\n",
        "    if not q:\n",
        "        return NOT_FOUND_MSG\n",
        "\n",
        "    # 0) Kullanıcı numara seçtiyse (1/2/3...)\n",
        "    if q.isdigit() and LAST_SUGGESTIONS:\n",
        "        k = int(q) - 1\n",
        "        if 0 <= k < len(LAST_SUGGESTIONS):\n",
        "            chosen = LAST_SUGGESTIONS[k]\n",
        "            LAST_SUGGESTIONS = []\n",
        "            return format_recipe_block(chosen)\n",
        "\n",
        "    # 1) Başlık sorularında: önce matcher dene\n",
        "    best_recipe = None\n",
        "    if \"MATCHER\" in globals() and MATCHER is not None:\n",
        "        exact = MATCHER.match(q)\n",
        "        if exact is not None:\n",
        "            LAST_SUGGESTIONS = []\n",
        "            best_recipe = exact\n",
        "\n",
        "    # 2) Matcher bulamazsa: FAISS ama \"güven\" filtresiyle\n",
        "    hits = []\n",
        "    if best_recipe is None:\n",
        "        hits = retrieve_recipes_safe(q, top_k=5, score_threshold=0.35, min_margin=0.02)\n",
        "\n",
        "        if hits:\n",
        "            best_score, cand = hits[0]   # (score, recipe)\n",
        "            overlap = _token_overlap(q, cand.title)\n",
        "\n",
        "            # >>> anti-sushi kuralı:\n",
        "            # overlap yoksa çok yüksek skor istemek zorundasın\n",
        "            ok = (best_score >= 0.45) or (best_score >= 0.38 and overlap >= 1)\n",
        "\n",
        "            if ok:\n",
        "                best_recipe = cand\n",
        "                LAST_SUGGESTIONS = []\n",
        "            else:\n",
        "                best_recipe = None\n",
        "\n",
        "    # 3) Hâlâ recipe yoksa: öneri listesi dön (STRICT: dataset başlıklarından)\n",
        "    if best_recipe is None:\n",
        "        sugg = MATCHER.suggest(q, top_n=6) if (\"MATCHER\" in globals() and MATCHER is not None) else []\n",
        "        LAST_SUGGESTIONS = sugg[:]  # kullanıcı 1/2/3 seçebilsin\n",
        "        return format_suggestions(sugg)\n",
        "\n",
        "    # 4) Guard: süre/derece/airfryer\n",
        "    if _TIME_Q_RE.search(q):\n",
        "        return (\n",
        "            \"Bu veri setinde **pişirme süresi / derece / airfryer ayarı** bilgisi yok.\\n\"\n",
        "            \"Ama ilgili tarifin malzemeleri ve yapılışı şu şekilde:\\n\\n\"\n",
        "            + format_recipe_block(best_recipe)\n",
        "        )\n",
        "\n",
        "    # 5) Guard: porsiyon\n",
        "    if _PORTION_Q_RE.search(q):\n",
        "        return (\n",
        "            \"Bu veri setinde **porsiyon/kaç kişilik** bilgisi yok.\\n\"\n",
        "            \"Ama uygun bir tarif olarak şunu getirebilirim:\\n\\n\"\n",
        "            + format_recipe_block(best_recipe)\n",
        "        )\n",
        "\n",
        "    # 6) “öner” -> LLM yok, direkt tarif\n",
        "    if _SUGGEST_Q_RE.search(q):\n",
        "        return \"Önerim:\\n\\n\" + format_recipe_block(best_recipe)\n",
        "\n",
        "    # 7) Tarif/malzeme/yapılış istiyorsa: LLM’e hiç gitme\n",
        "    if _RECIPE_REQ_RE.search(q) or (len(q.split()) <= 6):\n",
        "        return format_recipe_block(best_recipe)\n",
        "\n",
        "    # 8) LLM sadece follow-up için (context sadece kabul edilen recipe/hitler)\n",
        "    contexts = []\n",
        "    if hits:\n",
        "        # hits: [(score, recipe), ...]\n",
        "        for s, r in hits[:top_k]:\n",
        "            contexts.append(f\"[SCORE={s:.3f}]\\n{format_recipe_block(r)}\")\n",
        "    else:\n",
        "        contexts.append(format_recipe_block(best_recipe))\n",
        "    context_text = \"\\n\\n---\\n\\n\".join(contexts)\n",
        "\n",
        "    system = (\n",
        "        \"Sen bir yemek tarifi asistanısın.\\n\"\n",
        "        \"SADECE verilen CONTEXT içindeki bilgilere dayanarak cevap ver.\\n\"\n",
        "        f\"Eğer context yeterli değilse veya tarif yoksa aynen şunu yaz: {NOT_FOUND_MSG}\\n\"\n",
        "        \"Uydurma/ekleme yapma.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"Soru: {q}\\n\\nCONTEXT:\\n{context_text}\"},\n",
        "    ]\n",
        "    prompt = tokenizer_llm.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer_llm(prompt, return_tensors=\"pt\").to(model_llm.device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        out = model_llm.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            do_sample=False,\n",
        "            temperature=0.0,\n",
        "            repetition_penalty=1.05,\n",
        "            eos_token_id=tokenizer_llm.eos_token_id,\n",
        "            pad_token_id=tokenizer_llm.eos_token_id,\n",
        "        )\n",
        "\n",
        "    gen_ids = out[0][inputs[\"input_ids\"].shape[1]:]\n",
        "    text = tokenizer_llm.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    for marker in [\"<|user|>\", \"<|assistant|>\", \"<|system|>\"]:\n",
        "        if marker in text:\n",
        "            text = text.split(marker, 1)[0].strip()\n",
        "\n",
        "    if text.startswith(NOT_FOUND_MSG):\n",
        "        return NOT_FOUND_MSG\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "JQpFkuVUH38k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e50df477c1b845f09f2b535c01016517",
            "3178be02488c4a1c99af0531615beca9",
            "64e6dac1744845c1ac7f3c912b080440",
            "feefcd216c9d45a6b9f9bc18c8c549e1",
            "04152e4534154f5d86529d3d9fa599ea",
            "cd1b6b6f75d74c7da8edc673cc8c79bc",
            "65055092377e42deac005abd755ea5fc",
            "dd2410229054451e8e8182a17803a295",
            "aed2b00d14864d8894a419ec049b7fde",
            "9209f1ee1f52476c9b638d282b35af9f",
            "7dbc22b2844049feba23db42731227df"
          ]
        },
        "outputId": "b4c141d3-bec6-4053-f590-2ab0d9c8dae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e50df477c1b845f09f2b535c01016517"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "demo_rag = gr.Interface(\n",
        "    fn=rag_answer_guarded,\n",
        "    inputs=gr.Textbox(lines=2, label=\"Soru (örn: 'sodalı köfte tarifi')\"),\n",
        "    outputs=gr.Textbox(lines=25, label=\"Cevap\"),\n",
        "    title=\"Türkçe Yemek Tarifi Chatbot (Strict RAG)\",\n",
        "    description=\"Nefis Yemekler\"\n",
        "  )\n",
        "\n",
        "demo_rag.launch(share=True)"
      ],
      "metadata": {
        "id": "reRgOC3pH5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "72d3b2f3-af51-462e-9e48-5e71f35e208b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fdcf20e62358f40d00.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fdcf20e62358f40d00.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}